<head>
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Fanyu Wang|Personal Website</title>
  
<meta name="description" content="A showcase of Simply Docs by MarketingPipeline built using Simple.CSS">

<link rel="stylesheet" href="./assets/style.css">

<link rel="icon" href="./assets/images/favicon.png">
<link rel="apple-touch-icon" href="./assets/images/favicon.png">

 <!-- Facebook integration -->
<meta property="og:title" content="Fanyu Wang">
<meta property="og:image" content="./assets/images/OG_image.png">
<meta property="og:url" content="https://marketingpipeline.github.io/Simply-Docs/">
<meta property="og:type" content="article">
<meta property="og:site_name" content="Simple.css">
<meta property="og:description" content="A Simply Docs / Blog Template built using Simple.css.">

<!-- Twitter integration -->
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:title" content="Simply Docs | Demo">
<meta name="twitter:image" content="./assets/images/OG_image.jpg">
<meta name="twitter:url" content="https://marketingpipeline.github.io/Simply-Docs/">
<meta name="twitter:description" content="A Simply Docs / Blog Template built using Simple.css">
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.28.0/prism.min.js"></script>

  </head>
<header>
   <nav>
  <a href="mailto:fanyu_wang@stu.jiangnan.edu.cn">Email</a>

  <a href="https://twitter.com/fanyuuwang">Twitter</a>

  <a href="www.linkedin.com/in/fanyuuwang">Linkedin</a>
	   
  <a href="https://scholar.google.com/citations?user=og5_fesAAAAJ&hl">Google Scholar</a>
	   
  <a href="https://www.semanticscholar.org/author/Fanyu-Wang/113437495">Semantic Scholar</a>
	  

</nav>
<img src="./assets/images/w2c.png" width=800 alt="W2C" title="W2C Photo" />
      <h2>W2CSpace</h2>
      <p align="justify">As the foundation of current natural language processing methods, pre-trained language model has achieved excellent performance. However, the black-box structure of the deep neural network in pre-trained language models seriously limits the interpretability of the language modeling process. After revisiting the coupled requirement of deep neural representation and semantics logic of language modeling, a Word-Context-Coupled Space (W2CSpace) is proposed by introducing the alignment processing between uninterpretable neural representation and interpretable statistical logic. Moreover, a clustering process is also designed to connect the word- and context-level semantics. Specifically, an associative knowledge network (AKN), considered interpretable statistical logic, is introduced in the alignment process for word-level semantics. Furthermore, the context-relative distance is employed as the semantic feature for the downstream classifier, which is greatly different from the current uninterpretable semantic representations of pre-trained models. Our experiments for performance evaluation and interpretable analysis are executed on several types of datasets, including SIGHAN, Weibo, and ChnSenti. Wherein a novel evaluation strategy for the interpretability of machine learning models is first proposed. According to the experimental results, our language model can achieve better performance and highly credible interpretable ability compared to related state-of-the-art methods.</p>
    </header>
<main>
<h2>METHODOLOGY</h2>
<ul>
<li>‚ÄúWord-level semantics in W2CSpace is aligned with AKN distribution.‚Äù</li>
	<p>W2CSpace aims to realize interpretably language modeling by introducing context-aware language representations. The word-level semantics, mapped from BERT representations with a mapping network, are aligned with introduced statistical AKN distribution. With the training process for alignment process, the interpretable knowledge is ingested into mapped representations on word-level.</p>
<li>‚ÄúContext abstraction is realized by ùíå-means clustering with merge matrix.‚Äù</li>
	<p>Humans are able to recognize emotion from language, action, and so on (Barrett et al., 2007). Specifically, in linguistics, humans recognize emotion with the context in the given sentences. We use ùíå-means clustering process based on cosine distance for abstract context-level semantics from word-level semantics. A merge matrix is introduced on the clusters to establish the communication between different clusters, which reduce the impact of the ùëò number in ùëò-means for reasonable clustering process.</p>
<li>‚ÄúInput text are interpretably modeled based on context relations.‚Äù</li>
	<p>The input text are firstly mapped into word-level semantics in W2CSpace, and calculate the cosine distance with the context clusters, which named contextrelative distance. Context-relative distance is able to directly feed into downstream classifier in fine-tuning tasks with minimal modification.</p>
</ul>
<h2>Professional Affiliations</h2>
<ul>
<li align="justify">05/2020 - current: Research Assistant in ColeGroup, Key Laboratory of Media Design and Software Technology in Jiangsu Province</li>
<li align="justify">10/2020 - 05/2023: Student Member in ColeGroup, Key Laboratory of Media Design and Software Technology in Jiangsu Province</li>
</ul>
<h2>Publications</h2>
<ul>
<li align="justify">Fanyu Wang and Zhenping Xie. Constructing Character-Context-Coupled Space with Associative Knowledge for Interpretable Language Modeling. (Accepted) In Findings of 61th Annual Meeting of the Association for Computational
Linguistics. <a href="https://arxiv.org/abs/2305.11543">Link</a></li>
	
<li align="justify">Fanyu Wang and Zhenping Xie. An Adversarial Multi-Task Learning Method for Chinese Text Correction with Semantic Detection. In 31st International Conference on Artificial Neural Networks, (ICANN2022).Springer. Bristol,
England (Oral). <a href="https://link.springer.com/chapter/10.1007/978-3-031-15931-2_14">Link</a></li>

<li align="justify">Fanyu Wang, Huihui Shao and Zhenping Xie. AxBERT: An Explainable Chinese Spelling Correction Method Driven by Associative Knowledge Network. (Under Reviewing)</li>

<li align="justify">Tingting Li, Fanyu Wang (Co-first writer), Ying Zhou and Zhenping Xie. Visual illusion cognition dataset construction and recognition performance by deep neural networks. In 8th IEEE International Conference on Cloud Computing and Intelligence System (2022). Chengdu, China (Oral). <a href="https://ieeexplore.ieee.org/document/10016369">Link</a></li>
<li align="justify">Yulin Li, Zhenping Xie and Fanyu Wang. An associative knowledge network model for interpretable semantic representation of noun context. Complex Intell. Syst. (2022). <a href="https://link.springer.com/article/10.1007/s40747-022-00757-y">Link</a></li>
<li align="justify">Tingting Li, Fanyu Wang and Zhenping Xie. Space Topology Change Mostly Attracts Human Attention: An Implicit Feedback VR Driving System. In 30th IEEE Conference on Virtual Reality and 3D User Interfaces Abstract and Workshop (IEEEVRW 2023). <a href="https://ieeexplore.ieee.org/document/10108610">Link</a></li>
	
<li align="justify">Bin Zhai, Fanyu Wang and Zhenping Xie. An Explainable Enterprise Credit Evaluation Method Based on Logistic Regression Integration. In 2nd International Academic Conference on Blockchain, Information Technology and Smart Finance. (2023)</li>

<li align="justify">Jun Cao, Fanyu Wang and Zhenping Xie, et al. Imputation Algorithm for Multi view financial Data based on weighted random Forest. In 2nd International Conference on Urban Planning and Regional Economy, 2023.</li>

</ul>
</main>


<footer>
      <p>Created by Fanyu Wang Based on <a href="https://github.com/MarketingPipeline/Simply-Docs">Simply-Docs</a></p>
    </footer>
   
 <script src="https://cdn.jsdelivr.net/gh/MarketingPipeline/Markdown-Tag/markdown-tag.js"></script> 
